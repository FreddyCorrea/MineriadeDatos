{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6\n",
    "\n",
    "## SVM & Regularization\n",
    "\n",
    "\n",
    "For this homework we consider a set of observations on a number of red and white wine varieties involving their chemical properties and ranking by tasters. Wine industry shows a recent growth spurt as social drinking is on the rise. The price of wine depends on a rather abstract concept of wine appreciation by wine tasters, opinion among whom may have a high degree of variability. Pricing of wine depends on such a volatile factor to some extent. Another key factor in wine certification and quality assessment is physicochemical tests which are laboratory-based and takes into account factors like acidity, pH level, presence of sugar and other chemical properties. For the wine market, it would be of interest if human quality of tasting can be related to the chemical properties of wine so that certification and quality assessment and assurance process is more controlled.\n",
    "\n",
    "Two datasets are available of which one dataset is on red wine and have 1599 different varieties and the other is on white wine and have 4898 varieties. All wines are produced in a particular area of Portugal. Data are collected on 12 different properties of the wines one of which is Quality, based on sensory data, and the rest are on chemical properties of the wines including density, acidity, alcohol content etc. All chemical properties of wines are continuous variables. Quality is an ordinal variable with possible ranking from 1 (worst) to 10 (best). Each variety of wine is tasted by three independent tasters and the final rank assigned is the median rank given by the tasters.\n",
    "\n",
    "A predictive model developed on this data is expected to provide guidance to vineyards regarding quality and price expected on their produce without heavy reliance on volatility of wine tasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/Wine_data_red.csv')\n",
    "data_w = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/Wine_data_white.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.29</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.035</td>\n",
       "      <td>53.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.99567</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.054</td>\n",
       "      <td>27.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.99480</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.57</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>5.7</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.042</td>\n",
       "      <td>19.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.99460</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.42</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.27</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.041</td>\n",
       "      <td>24.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.99535</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.43</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.25</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.056</td>\n",
       "      <td>47.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.99610</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.47</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "3772            6.3             0.240         0.29            13.7      0.035   \n",
       "2921            6.7             0.390         0.31             2.7      0.054   \n",
       "1393            5.7             0.135         0.30             4.6      0.042   \n",
       "744             7.4             0.380         0.27             7.5      0.041   \n",
       "285             7.3             0.320         0.25             7.2      0.056   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "3772                 53.0                 134.0  0.99567  3.17       0.38   \n",
       "2921                 27.0                 202.0  0.99480  3.46       0.57   \n",
       "1393                 19.0                 101.0  0.99460  3.31       0.42   \n",
       "744                  24.0                 160.0  0.99535  3.17       0.43   \n",
       "285                  47.0                 180.0  0.99610  3.08       0.47   \n",
       "\n",
       "      alcohol  quality   type  \n",
       "3772     10.6        6  white  \n",
       "2921     10.5        6  white  \n",
       "1393      9.3        6  white  \n",
       "744      10.0        5  white  \n",
       "285       8.8        5  white  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_w.assign(type = 'white')\n",
    "\n",
    "data = data.append(data_r.assign(type = 'red'), ignore_index=True)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.1\n",
    "\n",
    "Show the frecuency table of the quality by type of wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type   quality\n",
       "red    3            10\n",
       "       4            53\n",
       "       5           681\n",
       "       6           638\n",
       "       7           199\n",
       "       8            18\n",
       "white  3            20\n",
       "       4           163\n",
       "       5          1457\n",
       "       6          2198\n",
       "       7           880\n",
       "       8           175\n",
       "       9             5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['type','quality']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.2\n",
    "\n",
    "* Standarized the features (not the quality)\n",
    "* Create a binary target for each type of wine\n",
    "* Create two Linear SVM's for the white and red wines, repectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.166089</td>\n",
       "      <td>-0.423183</td>\n",
       "      <td>0.284686</td>\n",
       "      <td>3.206929</td>\n",
       "      <td>-0.314975</td>\n",
       "      <td>0.815565</td>\n",
       "      <td>0.959976</td>\n",
       "      <td>2.102214</td>\n",
       "      <td>-1.359049</td>\n",
       "      <td>-0.546178</td>\n",
       "      <td>-1.418558</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.706073</td>\n",
       "      <td>-0.240949</td>\n",
       "      <td>0.147046</td>\n",
       "      <td>-0.807837</td>\n",
       "      <td>-0.200790</td>\n",
       "      <td>-0.931107</td>\n",
       "      <td>0.287618</td>\n",
       "      <td>-0.232332</td>\n",
       "      <td>0.506915</td>\n",
       "      <td>-0.277351</td>\n",
       "      <td>-0.831615</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.682458</td>\n",
       "      <td>-0.362438</td>\n",
       "      <td>0.559966</td>\n",
       "      <td>0.306208</td>\n",
       "      <td>-0.172244</td>\n",
       "      <td>-0.029599</td>\n",
       "      <td>-0.331660</td>\n",
       "      <td>0.134525</td>\n",
       "      <td>0.258120</td>\n",
       "      <td>-0.613385</td>\n",
       "      <td>-0.328521</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.011808</td>\n",
       "      <td>-0.666161</td>\n",
       "      <td>0.009406</td>\n",
       "      <td>0.642523</td>\n",
       "      <td>0.056126</td>\n",
       "      <td>0.928254</td>\n",
       "      <td>1.243074</td>\n",
       "      <td>0.301278</td>\n",
       "      <td>-0.177272</td>\n",
       "      <td>-0.882212</td>\n",
       "      <td>-0.496219</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.011808</td>\n",
       "      <td>-0.666161</td>\n",
       "      <td>0.009406</td>\n",
       "      <td>0.642523</td>\n",
       "      <td>0.056126</td>\n",
       "      <td>0.928254</td>\n",
       "      <td>1.243074</td>\n",
       "      <td>0.301278</td>\n",
       "      <td>-0.177272</td>\n",
       "      <td>-0.882212</td>\n",
       "      <td>-0.496219</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0      -0.166089         -0.423183     0.284686        3.206929  -0.314975   \n",
       "1      -0.706073         -0.240949     0.147046       -0.807837  -0.200790   \n",
       "2       0.682458         -0.362438     0.559966        0.306208  -0.172244   \n",
       "3      -0.011808         -0.666161     0.009406        0.642523   0.056126   \n",
       "4      -0.011808         -0.666161     0.009406        0.642523   0.056126   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "0             0.815565              0.959976  2.102214 -1.359049  -0.546178   \n",
       "1            -0.931107              0.287618 -0.232332  0.506915  -0.277351   \n",
       "2            -0.029599             -0.331660  0.134525  0.258120  -0.613385   \n",
       "3             0.928254              1.243074  0.301278 -0.177272  -0.882212   \n",
       "4             0.928254              1.243074  0.301278 -0.177272  -0.882212   \n",
       "\n",
       "    alcohol  quality   type  \n",
       "0 -1.418558        6  white  \n",
       "1 -0.831615        6  white  \n",
       "2 -0.328521        6  white  \n",
       "3 -0.496219        6  white  \n",
       "4 -0.496219        6  white  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "#scaler=StandardScaler()\n",
    "#data_scaled=scaler.fit_transform(data.drop(columns=['quality','type']))\n",
    "\n",
    "scaler=preprocessing.StandardScaler()\n",
    "data2 = pd.DataFrame(scaler.fit_transform(data.iloc[:,0:11]),columns=data.columns.values.tolist()[0:11])\n",
    "data2 = pd.concat([data2,data.iloc[:,11:13]], axis=1)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear un target binario para cada tipo de vino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "4898       0.142473          2.188833    -2.192833       -0.744778   0.569958   \n",
      "4899       0.451036          3.282235    -2.192833       -0.597640   1.197975   \n",
      "4900       0.451036          2.553300    -1.917553       -0.660699   1.026697   \n",
      "4901       3.073817         -0.362438     1.661085       -0.744778   0.541412   \n",
      "4902       0.142473          2.188833    -2.192833       -0.744778   0.569958   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
      "4898            -1.100140             -1.446359  1.034993  1.813090   \n",
      "4899            -0.311320             -0.862469  0.701486 -0.115073   \n",
      "4900            -0.874763             -1.092486  0.768188  0.258120   \n",
      "4901            -0.762074             -0.986324  1.101694 -0.363868   \n",
      "4902            -1.100140             -1.446359  1.034993  1.813090   \n",
      "\n",
      "      sulphates   alcohol  quality type  target  \n",
      "4898   0.193097 -0.915464        5  red       0  \n",
      "4899   0.999579 -0.580068        5  red       0  \n",
      "4900   0.797958 -0.580068        5  red       0  \n",
      "4901   0.327510 -0.580068        6  red       1  \n",
      "4902   0.193097 -0.915464        5  red       0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\usuario\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>type</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.166089</td>\n",
       "      <td>-0.423183</td>\n",
       "      <td>0.284686</td>\n",
       "      <td>3.206929</td>\n",
       "      <td>-0.314975</td>\n",
       "      <td>0.815565</td>\n",
       "      <td>0.959976</td>\n",
       "      <td>2.102214</td>\n",
       "      <td>-1.359049</td>\n",
       "      <td>-0.546178</td>\n",
       "      <td>-1.418558</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.706073</td>\n",
       "      <td>-0.240949</td>\n",
       "      <td>0.147046</td>\n",
       "      <td>-0.807837</td>\n",
       "      <td>-0.200790</td>\n",
       "      <td>-0.931107</td>\n",
       "      <td>0.287618</td>\n",
       "      <td>-0.232332</td>\n",
       "      <td>0.506915</td>\n",
       "      <td>-0.277351</td>\n",
       "      <td>-0.831615</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.682458</td>\n",
       "      <td>-0.362438</td>\n",
       "      <td>0.559966</td>\n",
       "      <td>0.306208</td>\n",
       "      <td>-0.172244</td>\n",
       "      <td>-0.029599</td>\n",
       "      <td>-0.331660</td>\n",
       "      <td>0.134525</td>\n",
       "      <td>0.258120</td>\n",
       "      <td>-0.613385</td>\n",
       "      <td>-0.328521</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.011808</td>\n",
       "      <td>-0.666161</td>\n",
       "      <td>0.009406</td>\n",
       "      <td>0.642523</td>\n",
       "      <td>0.056126</td>\n",
       "      <td>0.928254</td>\n",
       "      <td>1.243074</td>\n",
       "      <td>0.301278</td>\n",
       "      <td>-0.177272</td>\n",
       "      <td>-0.882212</td>\n",
       "      <td>-0.496219</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.011808</td>\n",
       "      <td>-0.666161</td>\n",
       "      <td>0.009406</td>\n",
       "      <td>0.642523</td>\n",
       "      <td>0.056126</td>\n",
       "      <td>0.928254</td>\n",
       "      <td>1.243074</td>\n",
       "      <td>0.301278</td>\n",
       "      <td>-0.177272</td>\n",
       "      <td>-0.882212</td>\n",
       "      <td>-0.496219</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0      -0.166089         -0.423183     0.284686        3.206929  -0.314975   \n",
       "1      -0.706073         -0.240949     0.147046       -0.807837  -0.200790   \n",
       "2       0.682458         -0.362438     0.559966        0.306208  -0.172244   \n",
       "3      -0.011808         -0.666161     0.009406        0.642523   0.056126   \n",
       "4      -0.011808         -0.666161     0.009406        0.642523   0.056126   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "0             0.815565              0.959976  2.102214 -1.359049  -0.546178   \n",
       "1            -0.931107              0.287618 -0.232332  0.506915  -0.277351   \n",
       "2            -0.029599             -0.331660  0.134525  0.258120  -0.613385   \n",
       "3             0.928254              1.243074  0.301278 -0.177272  -0.882212   \n",
       "4             0.928254              1.243074  0.301278 -0.177272  -0.882212   \n",
       "\n",
       "    alcohol  quality   type  target  \n",
       "0 -1.418558        6  white       1  \n",
       "1 -0.831615        6  white       1  \n",
       "2 -0.328521        6  white       1  \n",
       "3 -0.496219        6  white       1  \n",
       "4 -0.496219        6  white       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datared=data2[data2['type'] == 'red']\n",
    "datared['target']=np.where(datared['quality']>5, 1, 0)\n",
    "print(datared.head())\n",
    "\n",
    "###################################\n",
    "\n",
    "datawhite=data2[data2['type'] == 'white']\n",
    "datawhite['target']=np.where(datawhite['quality']>5, 1, 0)\n",
    "datawhite.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM Target red wine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "validation_size = 0.30\n",
    "seed = 1\n",
    "X_trainred, X_validationred, Y_trainred, Y_validationred = train_test_split(datared.iloc[:,0:11], datared.loc[:,['target']],test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC # \"Support Vector Classifier\"\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_trainred, Y_trainred)\n",
    "print(clf.score(X_validationred,Y_validationred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM Target white wine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "validation_size = 0.30\n",
    "seed = 1\n",
    "X_trainwhite, X_validationwhite, Y_trainwhite, Y_validationwhite = train_test_split(datawhite.iloc[:,0:11], datawhite.loc[:,['target']],test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7442176870748299\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_trainwhite, Y_trainwhite)\n",
    "print(clf.score(X_validationwhite,Y_validationwhite))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos modelos poseen un buen ajuste y significativamente igual, aunque el modelo para el vino blanco es levemente mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.3\n",
    "\n",
    "Test the two SVM's using the different kernels (‘poly’, ‘rbf’, ‘sigmoid’)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para el vino Rojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "validation_size = 0.30\n",
    "seed = 1\n",
    "X_trainred, X_validationred, Y_trainred, Y_validationred = train_test_split(datared.iloc[:,0:11], datared.loc[:,['target']],test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7354166666666667\n",
      "0.7375\n",
      "0.6270833333333333\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "clf = SVC(kernel='poly')\n",
    "clf.fit(X_trainred, Y_trainred)\n",
    "print(clf.score(X_validationred, Y_validationred))\n",
    "\n",
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_trainred, Y_trainred)\n",
    "print(clf.score(X_validationred, Y_validationred))\n",
    "\n",
    "clf = SVC(kernel='sigmoid')\n",
    "clf.fit(X_trainred, Y_trainred)\n",
    "print(clf.score(X_validationred, Y_validationred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El kernel sigmoid no es recomendable, sin embargo, el kernel poly o rbf resultan significativamente igual de efectivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para el vino Blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "validation_size = 0.30\n",
    "seed = 1\n",
    "X_trainwhite, X_validationwhite, Y_trainwhite, Y_validationwhite = train_test_split(datawhite.iloc[:,0:11], datawhite.loc[:,['target']],test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7394557823129252\n",
      "0.7707482993197279\n",
      "0.6612244897959184\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "clf = SVC(kernel='poly')\n",
    "clf.fit(X_trainwhite, Y_trainwhite)\n",
    "print(clf.score(X_validationwhite, Y_validationwhite))\n",
    "\n",
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_trainwhite, Y_trainwhite)\n",
    "print(clf.score(X_validationwhite, Y_validationwhite))\n",
    "\n",
    "clf = SVC(kernel='sigmoid')\n",
    "clf.fit(X_trainwhite, Y_trainwhite)\n",
    "print(clf.score(X_validationwhite, Y_validationwhite))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejopr modelo lo genera el kernel rbf. Una vez más el modelo de kernel sigmoid es el más bajo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.4\n",
    "Using the best SVM find the parameters that gives the best performance\n",
    "\n",
    "'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7395833333333334\n",
      "(0.1, 0.01)\n",
      "0.5208333333333334\n",
      "(0.1, 0.001)\n",
      "0.5208333333333334\n",
      "(0.1, 0.0001)\n",
      "0.7458333333333333\n",
      "(1, 0.01)\n",
      "0.73125\n",
      "(1, 0.001)\n",
      "0.5208333333333334\n",
      "(1, 0.0001)\n",
      "0.7479166666666667\n",
      "(10, 0.01)\n",
      "0.7354166666666667\n",
      "(10, 0.001)\n",
      "0.7270833333333333\n",
      "(10, 0.0001)\n",
      "0.7333333333333333\n",
      "(100, 0.01)\n",
      "0.73125\n",
      "(100, 0.001)\n",
      "0.7375\n",
      "(100, 0.0001)\n",
      "0.7208333333333333\n",
      "(1000, 0.01)\n",
      "0.7479166666666667\n",
      "(1000, 0.001)\n",
      "0.7333333333333333\n",
      "(1000, 0.0001)\n"
     ]
    }
   ],
   "source": [
    "for i in [0.1, 1, 10, 100, 1000]:\n",
    "    for j in [0.01, 0.001, 0.0001]:\n",
    "        clf = SVC(kernel='rbf',C=i,gamma=j)\n",
    "        clf.fit(X_trainred, Y_trainred)\n",
    "        print(clf.score(X_validationred, Y_validationred))\n",
    "        print((i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6836734693877551\n",
      "(0.1, 0.01)\n",
      "0.6727891156462585\n",
      "(0.1, 0.001)\n",
      "0.6727891156462585\n",
      "(0.1, 0.0001)\n",
      "0.7510204081632653\n",
      "(1, 0.01)\n",
      "0.6850340136054421\n",
      "(1, 0.001)\n",
      "0.6727891156462585\n",
      "(1, 0.0001)\n",
      "0.7598639455782313\n",
      "(10, 0.01)\n",
      "0.7448979591836735\n",
      "(10, 0.001)\n",
      "0.6843537414965987\n",
      "(10, 0.0001)\n",
      "0.7700680272108843\n",
      "(100, 0.01)\n",
      "0.753061224489796\n",
      "(100, 0.001)\n",
      "0.7442176870748299\n",
      "(100, 0.0001)\n",
      "0.7639455782312925\n",
      "(1000, 0.01)\n",
      "0.7585034013605442\n",
      "(1000, 0.001)\n",
      "0.7462585034013606\n",
      "(1000, 0.0001)\n"
     ]
    }
   ],
   "source": [
    "for i in [0.1, 1, 10, 100, 1000]:\n",
    "    for j in [0.01, 0.001, 0.0001]:\n",
    "        clf = SVC(kernel='rbf',C=i,gamma=j)\n",
    "        clf.fit(X_trainwhite, Y_trainwhite)\n",
    "        print(clf.score(X_validationwhite, Y_validationwhite))\n",
    "        print((i,j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El acuraccy mas alto lo generan los parámetros (C=100, Gamma=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.5\n",
    "\n",
    "Compare the results with other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4970760233918129\n",
      "0.7590361445783133\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics\n",
    "validation_size = 0.30\n",
    "seed = 1\n",
    "\n",
    "X_trainred, X_validationred, Y_trainred, Y_validationred = train_test_split(datared.iloc[:,0:11], datared.loc[:,['target']],test_size=validation_size, random_state=seed)\n",
    "X_trainwhite, X_validationwhite, Y_trainwhite, Y_validationwhite = train_test_split(datawhite.iloc[:,0:11], datawhite.loc[:,['target']],test_size=validation_size, random_state=seed)\n",
    "\n",
    "##################wine white\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LogisticRegression()\n",
    "regr.fit(X_trainwhite, Y_trainwhite)\n",
    "yest = regr.predict(X_validationred)\n",
    "print(metrics.f1_score(y_true=Y_validationred, y_pred=yest, labels=None, pos_label=1, average='binary', sample_weight=None))\n",
    "\n",
    "\n",
    "##################wine red\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LogisticRegression()\n",
    "regr.fit(X_trainred, Y_trainred)\n",
    "yest = regr.predict(X_validationred)\n",
    "\n",
    "print(metrics.f1_score(y_true=Y_validationred, y_pred=yest, labels=None, pos_label=1, average='binary', sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando con una regresion logistica, se tiene que el acuraccy de la logistica es 2 unidades menor que el SVM con kernel rbf(C=100, Gamma=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.6\n",
    "\n",
    "\n",
    "* Train a linear regression to predict wine quality (Continous)\n",
    "\n",
    "* Analyze the coefficients\n",
    "\n",
    "* Evaluate the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "validation_size = 0.30\n",
    "seed = 1\n",
    "X_trainwhite, X_validationwhite, Y_trainwhite, Y_validationwhite = train_test_split(datawhite.iloc[:,0:11], datawhite.loc[:,['quality']],test_size=validation_size, random_state=seed)\n",
    "\n",
    "X_trainred, X_validationred, Y_trainred, Y_validationred = train_test_split(datared.iloc[:,0:11], datared.loc[:,['quality']],test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.06555822 -0.32875555  0.00041701  0.3747364  -0.01845062  0.05113925\n",
      "   0.00241766 -0.40297539  0.10072528  0.08578262  0.26270976]]\n",
      "[[ 0.05944053 -0.19366397 -0.0418161   0.07846098 -0.0632785   0.10775566\n",
      "  -0.21358157 -0.09779576 -0.06030107  0.13199705  0.31859006]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics\n",
    "\n",
    "##################wine white\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_trainwhite, Y_trainwhite)\n",
    "print(regr.coef_)\n",
    "\n",
    "##################wine red\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_trainred, Y_trainred)\n",
    "print(regr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parametros son similares respecto al signo para los dos tipos de vino. Sin embargo el efecto de la variable \"total sulfur dioxide\" genera una disminución en la calidad para el vino blanco, mietras que para el vino rojo mejora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6439937591433719\n",
      "0.762208199957938\n"
     ]
    }
   ],
   "source": [
    "###### red wine\n",
    "\n",
    "y_pred = regr.predict(X_validationred)\n",
    "#print(len(y_pred))\n",
    "print(np.sqrt(metrics.mean_squared_error(y_true=Y_validationred, y_pred=y_pred)))\n",
    "\n",
    "###### white wine\n",
    "\n",
    "y_pred = regr.predict(X_validationwhite)\n",
    "#print(len(y_pred))\n",
    "print(np.sqrt(metrics.mean_squared_error(y_true=Y_validationwhite, y_pred=y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluando RMSE obtenemos que el modelo asociado al vino rojo tiene menor sesgo y menor variabilidad, respecto a los parámetros poblacionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.7\n",
    "\n",
    "* Estimate a ridge regression with alpha equals 0.1 and 1.\n",
    "* Compare the coefficients with the linear regression\n",
    "* Evaluate the RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Estimate a ridge regression with alpha equals 0.1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05942888 -0.19365658 -0.04179569  0.07832738 -0.06327805  0.1076409\n",
      "  -0.21344237 -0.09776285 -0.06027854  0.13198763  0.31857531]]\n",
      "0.6439868128367477\n",
      "[[ 0.0593282  -0.19358894 -0.04161182  0.07714916 -0.06327421  0.10661674\n",
      "  -0.21220094 -0.09747942 -0.06007377  0.13190387  0.31843672]]\n",
      "0.6439252068900702\n",
      "[[ 0.06540763 -0.32874012  0.00041575  0.37446976 -0.01848657  0.05115849\n",
      "   0.00238572 -0.40256107  0.10064042  0.08574872  0.26287495]]\n",
      "0.7338479601575529\n",
      "[[ 0.06407032 -0.32859952  0.00040506  0.37210004 -0.01880684  0.05132961\n",
      "   0.00210119 -0.39888136  0.09988671  0.0854474   0.26433949]]\n",
      "0.7338604890326101\n"
     ]
    }
   ],
   "source": [
    "##################wine red\n",
    "\n",
    "for i in (0.1,1):\n",
    "    regr = linear_model.Ridge(alpha=i)\n",
    "    regr.fit(X_trainred, Y_trainred)\n",
    "    print(regr.coef_)\n",
    "    \n",
    "    ##############################\n",
    "    \n",
    "    y_pred = regr.predict(X_validationred)\n",
    "    #print(len(y_pred))\n",
    "    print(np.sqrt(metrics.mean_squared_error(y_true=Y_validationred, y_pred=y_pred)))\n",
    "\n",
    "##################wine white\n",
    "\n",
    "for i in (0.1,1):\n",
    "    regr = linear_model.Ridge(alpha=i)\n",
    "    regr.fit(X_trainwhite, Y_trainwhite)\n",
    "    print(regr.coef_)\n",
    "    \n",
    "    ################################\n",
    "    \n",
    "    y_pred = regr.predict(X_validationwhite)\n",
    "    #print(len(y_pred))\n",
    "    print(np.sqrt(metrics.mean_squared_error(y_true=Y_validationwhite, y_pred=y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el vino rojo no existen diferencias en el modelamiento, causadas por el cambio del parámetro. Adicionalmente, las estimaciones coinciden con las de la regresion lineal. Analogamente para el vino blanco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.8\n",
    "\n",
    "* Estimate a lasso regression with alpha equals 0.01, 0.1 and 1.\n",
    "* Compare the coefficients with the linear regression\n",
    "* Evaluate the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01226652 -0.1897616  -0.01707966 -0.         -0.0592588   0.02327915\n",
      " -0.13111967 -0.         -0.05754687  0.11666119  0.3435326 ]\n",
      "0.6396859531114644\n",
      "[ 0.         -0.16292194  0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.          0.03914364  0.26626377]\n",
      "0.6589161423746291\n",
      "[ 0. -0.  0.  0. -0. -0. -0. -0. -0.  0.  0.]\n",
      "0.7829719488451381\n",
      "[-0.         -0.31333648 -0.          0.21021576 -0.01357812  0.04749377\n",
      " -0.         -0.15871166  0.04980016  0.05065729  0.36057526]\n",
      "0.7364919779763596\n",
      "[-0.         -0.06856176  0.          0.         -0.          0.\n",
      " -0.         -0.          0.          0.          0.2849531 ]\n",
      "0.7697147271118832\n",
      "[-0. -0. -0. -0. -0.  0. -0. -0.  0.  0.  0.]\n",
      "0.8630965486563801\n"
     ]
    }
   ],
   "source": [
    "##################wine red\n",
    "\n",
    "for i in (0.01,0.1,1):\n",
    "    regr = linear_model.Lasso(alpha=i)\n",
    "    regr.fit(X_trainred, Y_trainred)\n",
    "    print(regr.coef_)\n",
    "    \n",
    "    ##############################\n",
    "    \n",
    "    y_pred = regr.predict(X_validationred)\n",
    "    #print(len(y_pred))\n",
    "    print(np.sqrt(metrics.mean_squared_error(y_true=Y_validationred, y_pred=y_pred)))\n",
    "\n",
    "##################wine white\n",
    "\n",
    "for i in (0.01,0.1,1):\n",
    "    regr = linear_model.Lasso(alpha=i)\n",
    "    regr.fit(X_trainwhite, Y_trainwhite)\n",
    "    print(regr.coef_)\n",
    "    \n",
    "    ################################\n",
    "    \n",
    "    y_pred = regr.predict(X_validationwhite)\n",
    "    #print(len(y_pred))\n",
    "    print(np.sqrt(metrics.mean_squared_error(y_true=Y_validationwhite, y_pred=y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los mejores modelos, tanto para el vino rojo como para el blanco, estiman los coeficientes en cero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.9\n",
    "\n",
    "* Create a binary target\n",
    "\n",
    "* Train a logistic regression to predict wine quality (binary)\n",
    "\n",
    "* Analyze the coefficients\n",
    "\n",
    "* Evaluate the f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.07741844 -1.1688188  -0.00921275  0.65162701 -0.045305    0.14503144\n",
      "  -0.04218935 -0.51482612  0.10039263  0.24927659  1.02890916]]\n",
      "0.4970760233918129\n",
      "[[ 2.61368864e-01 -5.66454826e-01 -2.33370022e-01  3.38300395e-01\n",
      "  -1.00790078e-01  4.39323907e-01 -9.88958503e-01 -2.55647069e-01\n",
      "   8.07172927e-04  3.93241629e-01  9.72876423e-01]]\n",
      "0.7590361445783133\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics\n",
    "validation_size = 0.30\n",
    "seed = 1\n",
    "\n",
    "X_trainred, X_validationred, Y_trainred, Y_validationred = train_test_split(datared.iloc[:,0:11], datared.loc[:,['target']],test_size=validation_size, random_state=seed)\n",
    "X_trainwhite, X_validationwhite, Y_trainwhite, Y_validationwhite = train_test_split(datawhite.iloc[:,0:11], datawhite.loc[:,['target']],test_size=validation_size, random_state=seed)\n",
    "\n",
    "##################wine white\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LogisticRegression()\n",
    "regr.fit(X_trainwhite, Y_trainwhite)\n",
    "print(regr.coef_)\n",
    "yest = regr.predict(X_validationred)\n",
    "\n",
    "print(metrics.f1_score(y_true=Y_validationred, y_pred=yest, labels=None, pos_label=1, average='binary', sample_weight=None))\n",
    "\n",
    "\n",
    "##################wine red\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LogisticRegression()\n",
    "regr.fit(X_trainred, Y_trainred)\n",
    "print(regr.coef_)\n",
    "\n",
    "yest = regr.predict(X_validationred)\n",
    "\n",
    "print(metrics.f1_score(y_true=Y_validationred, y_pred=yest, labels=None, pos_label=1, average='binary', sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.10\n",
    "\n",
    "* Estimate a regularized logistic regression using:\n",
    "* C = 0.01, 0.1 & 1.0\n",
    "* penalty = ['l1, 'l2']\n",
    "* Compare the coefficients and the f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -0.05770295  0.          0.          0.          0.\n",
      "  -0.02445905  0.          0.          0.13168017  0.5080994 ]]\n",
      "(0.01, 'l1')\n",
      "0.5961453881233794\n",
      "[[ 0.12218078 -0.34153925 -0.01806231  0.00151835 -0.11310108 -0.00122011\n",
      "  -0.32696745 -0.15649656  0.05378758  0.28352782  0.57843035]]\n",
      "(0.01, 'l2')\n",
      "0.5392925024850921\n",
      "[[ 0.07517868 -0.50717001 -0.09401161  0.         -0.08399181  0.0259073\n",
      "  -0.51161715  0.          0.          0.30207069  0.98919541]]\n",
      "(0.1, 'l1')\n",
      "0.5213469822443547\n",
      "[[ 0.22885225 -0.53018248 -0.18951441  0.17931325 -0.10556019  0.25917318\n",
      "  -0.73914629 -0.22485645  0.01411761  0.37199946  0.91393983]]\n",
      "(0.1, 'l2')\n",
      "0.519830903429601\n",
      "[[ 0.22594753 -0.56919789 -0.22110531  0.27775398 -0.09991246  0.42385985\n",
      "  -0.95619776 -0.19462234 -0.01428251  0.37910998  0.9957703 ]]\n",
      "(1, 'l1')\n",
      "0.520573377309497\n",
      "[[ 2.61368864e-01 -5.66454826e-01 -2.33370022e-01  3.38300395e-01\n",
      "  -1.00790078e-01  4.39323907e-01 -9.88958503e-01 -2.55647069e-01\n",
      "   8.07172927e-04  3.93241629e-01  9.72876423e-01]]\n",
      "(1, 'l2')\n",
      "0.5212622467436778\n",
      "DIIVISION\n",
      "[[ 0.         -0.75339508  0.          0.08708506  0.          0.02391949\n",
      "   0.          0.          0.          0.          0.82284978]]\n",
      "(0.01, 'l1')\n",
      "0.5294644786128219\n",
      "[[-0.11732886 -0.741801    0.02342681  0.3528247  -0.16563395  0.14138775\n",
      "  -0.06214251 -0.29864926  0.05628004  0.14574321  0.76960861]]\n",
      "(0.01, 'l2')\n",
      "0.5169223402296192\n",
      "[[-0.16460112 -1.13987629  0.          0.42580393 -0.04992121  0.11690274\n",
      "   0.         -0.19282817  0.02436446  0.17442612  1.13443296]]\n",
      "(0.1, 'l1')\n",
      "0.5146724024234341\n",
      "[[-0.10236052 -1.09853028 -0.00429775  0.57197606 -0.07097911  0.14988506\n",
      "  -0.05553246 -0.42341048  0.08351873  0.23051119  1.01503426]]\n",
      "(0.1, 'l2')\n",
      "0.5128456703004278\n",
      "[[-0.08277614 -1.17383454 -0.00801773  0.63947879 -0.04274931  0.13955729\n",
      "  -0.03217909 -0.49564797  0.09510411  0.24334926  1.04033962]]\n",
      "(1, 'l1')\n",
      "0.5133299135276118\n",
      "[[-0.07741844 -1.1688188  -0.00921275  0.65162701 -0.045305    0.14503144\n",
      "  -0.04218935 -0.51482612  0.10039263  0.24927659  1.02890916]]\n",
      "(1, 'l2')\n",
      "0.5131849635809222\n"
     ]
    }
   ],
   "source": [
    "### red wine\n",
    "\n",
    "for i in [0.01,0.1, 1]:\n",
    "    for j in ['l1', 'l2']:\n",
    "        # try C=0.1 with L1 penalty\n",
    "        logreg = linear_model.LogisticRegression(C=i, penalty=j)\n",
    "        logreg.fit(X_trainred, Y_trainred)\n",
    "        \n",
    "        print(logreg.coef_)\n",
    "        print((i,j))\n",
    "        # generate predicted probabilities and calculate log loss\n",
    "        y_pred_prob = logreg.predict_proba(X_validationred)\n",
    "        print(metrics.log_loss(Y_validationred, y_pred_prob))\n",
    "        \n",
    "        \n",
    "####################################\n",
    "\n",
    "\n",
    "print('DIIVISION')\n",
    "\n",
    "### white wine\n",
    "\n",
    "for i in [0.01,0.1, 1]:\n",
    "    for j in ['l1', 'l2']:\n",
    "        # try C=0.1 with L1 penalty\n",
    "        logreg = linear_model.LogisticRegression(C=i, penalty=j)\n",
    "        logreg.fit(X_trainwhite, Y_trainwhite) \n",
    "        print(logreg.coef_)\n",
    "        print((i,j))\n",
    "        # generate predicted probabilities and calculate log loss\n",
    "        y_pred_prob = logreg.predict_proba(X_validationwhite)\n",
    "        print(metrics.log_loss(Y_validationwhite, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el vino rojo, los parámetros que mejor minimmizan la funcion de costo son 0.1 & 'l2', mientras que para el vino blanco no hay diferencias significativas en la minimizacion variando los parámetros de estimación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
